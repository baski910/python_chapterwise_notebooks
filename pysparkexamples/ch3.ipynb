{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e53788e-2d53-4f61-8ef0-7c4975e6acb4",
   "metadata": {},
   "source": [
    "<h2>SparkContext</h2>\n",
    "<p>\n",
    "<strong>pyspark.SparkContext</strong> is an entry point to the PySpark functionality that is used to communicate with the cluster and to create an RDD, accumulator, and broadcast variables. \n",
    "</p>\n",
    "<p>\n",
    "The Spark driver program creates and uses SparkContext to connect to the cluster manager to submit PySpark jobs, and know what resource manager (YARN, Mesos, or Standalone) to communicate to. It is the heart of the PySpark application.\n",
    "</p>\n",
    "<h2>1. SparkContext in PySpark shell</h2>\n",
    "<p>\n",
    "By default, PySpark shell creates and provides sc object, which is an instance of the SparkContext class. We can directly use this object where required without the need to create.\n",
    "</p>\n",
    "<p><strong>Example reading text file using SparkContext</strong></p>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    ">>sc.textFile(path_of_the_file)\n",
    "</p>\n",
    "<h2>2. Create SparkContext in PySpark</h2>\n",
    "<p>Creating a SparkSession creates a SparkContext internally and exposes the sparkContext variable to use.(above version 2.0)\n",
    "</p>\n",
    "<p>\n",
    "Creating a SparkSession creates a SparkContext internally and exposes the sparkContext variable to use.\n",
    "</p>\n",
    "<p height=\"300\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "# Create SparkSession from builder</br>\n",
    "from pyspark.sql import SparkSession</br>\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\</br>\n",
    "                    .appName('SparkByExamples.com') \\</br>\n",
    "                    .getOrCreate()</br>\n",
    "print(spark.sparkContext)</br>\n",
    "print(\"Spark App Name : \"+ spark.sparkContext.appName)</br>\n",
    "</p>\n",
    "<h2>3. Stop PySpark SparkContext</h2>\n",
    "<p>\n",
    "You can stop the SparkContext by calling the stop() method. As explained above you can have only one SparkContext per JVM. If you wanted to create another, you need to shutdown it first by using stop() method and create a new SparkContext.\n",
    "</p>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "# SparkContext stop() method</br>\n",
    "spark.sparkContext.stop()</br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9238db5-ebc8-4683-af3c-d2c116c112ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
