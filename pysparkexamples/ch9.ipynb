{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792220b4-6b86-4312-b584-b0994af5d772",
   "metadata": {},
   "source": [
    "<h2>PySpark Join Types</h2>\n",
    "<p>PySpark Join is used to combine two DataFrames and by chaining these you can join multiple DataFrames; it supports all basic join type operations available in traditional <strong>SQL like INNER, LEFT OUTER, RIGHT OUTER, LEFT ANTI, LEFT SEMI, CROSS, SELF JOIN.</strong>\n",
    "</p>\n",
    "<h2>1. PySpark Join Syntax</h2>\n",
    "<p>PySpark SQL join has a below syntax and it can be accessed directly from DataFrame.</p>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Syntax</br>\n",
    "join(self, other, on=None, how=None)</br>\n",
    "</p>\n",
    "<p>You can also write Join expression by adding <strong>where() and filter()</strong> methods on DataFrame and can have Join on multiple columns.</p>\n",
    "<h2>2. PySpark Join Types</h2>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Prepare data</br>\n",
    "import pyspark</br>\n",
    "from pyspark.sql import SparkSession</br>\n",
    "</br>\n",
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\</br>\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\</br>\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\</br>\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\</br>\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\</br>\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\</br>\n",
    "  ]</br>\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\</br>\n",
    "       \"emp_dept_id\",\"gender\",\"salary\"]</br>\n",
    "</br>\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)</br>\n",
    "empDF.printSchema()</br>\n",
    "empDF.show(truncate=False)</br>\n",
    "</br>\n",
    "dept = [(\"Finance\",10), \\</br>\n",
    "    (\"Marketing\",20), \\</br>\n",
    "    (\"Sales\",30), \\</br>\n",
    "    (\"IT\",40) \\</br>\n",
    "  ]</br>\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]</br>\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)</br>\n",
    "deptDF.printSchema()</br>\n",
    "deptDF.show(truncate=False)</br>\n",
    "</p>\n",
    "<h2>4. PySpark Inner Join DataFrame</h2>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Inner join\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\") \\</br>\n",
    "     .show(truncate=False)</br>\n",
    "</p>\n",
    "<h2>5. PySpark Left Outer Join</h2>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Left outer join</br>\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\")</br>\n",
    "    .show(truncate=False)</br>\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftouter\")</br>\n",
    "    .show(truncate=False)</br>\n",
    "</p>\n",
    "<h2>6. Right Outer Join</h2>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Right outer join</br>\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\") \\</br>\n",
    "   .show(truncate=False)</br>\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"rightouter\") \\</br>\n",
    "   .show(truncate=False)</br>\n",
    "</p>\n",
    "<h2>7. PySpark Full Outer Join</h2>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Full outer join</br>\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\") \\</br>\n",
    "    .show(truncate=False)</br>\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"full\") \\</br>\n",
    "    .show(truncate=False)</br>\n",
    "empDF.join(deptDF,empDF.emp_dept</br>\n",
    "</p>\n",
    "<h2>8. Left Semi Join</h2>\n",
    "<p>A Left Semi Join in PySpark returns only the rows from the left DataFrame (the first DataFrame mentioned in the join operation) where there is a match with the right DataFrame (the second DataFrame).</p>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Left semi join</br>\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftsemi\") \\</br>\n",
    "   .show(truncate=False)</br>\n",
    "</p>\n",
    "<h2>9. Left Anti Join</h2>\n",
    "<p>A Left Anti Join in PySpark returns only the rows from the left DataFrame (the first DataFrame mentioned in the join operation) where there is no match with the right DataFrame (the second DataFrame). </p>\n",
    "<p height=\"50\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Left anti join</br>\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftanti\") \\</br>\n",
    "   .show(truncate=False)</br>\n",
    "</p>\n",
    "<h2>10. PySpark Self Join</h2>\n",
    "<p height=\"100\" width=\"100%\" style=\"background:black;font-size:20px;color:white\">\n",
    "</br>\n",
    "# Self join</br>\n",
    "empDF.alias(\"emp1\").join(empDF.alias(\"emp2\"), \\</br>\n",
    "    col(\"emp1.superior_emp_id\") == col(\"emp2.emp_id\"),\"inner\") \\</br>\n",
    "    .select(col(\"emp1.emp_id\"),col(\"emp1.name\"), \\</br>\n",
    "      col(\"emp2.emp_id\").alias(\"superior_emp_id\"), \\</br>\n",
    "      col(\"emp2.name\").alias(\"superior_emp_name\")) \\</br>\n",
    "   .show(truncate=False)</br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e0317-2d64-4d30-86cb-fffc8e7ddcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
